{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the code from the kaggle kernel [Deep_1: 0.91 acc](https://www.kaggle.com/potamitis/deep-1-0-91-acc), which has been released under Apache License 2.0 Copyright of Ilyas Potamitis. The code is applied to a smaller dataset, so the accuracy on the validation set is pretty low, even though the accuracy on the test set goes above .90.\n",
    "\n",
    "The notebook uses the deep learning library [keras](https://keras.io/) which wraps different deep learning frameworks. If you do not have it you can install it by uncommenting the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install --yes keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Deep learning on time domain samples. Acc on 20% hold out test set is 91%\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Conv1D, GlobalAveragePooling1D, MaxPooling1D\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5181, 5000)\n"
     ]
    }
   ],
   "source": [
    "# reading the stored data\n",
    "X = np.load('data/X.npy')\n",
    "y = np.load('data/y.npy')\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 8000\n",
    "target_names = ['Ae. aegypti', 'Ae. albopictus', 'An. gambiae', 'An. arabiensis', 'C. pipiens', 'C. quinquefasciatus']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2018)\n",
    "\n",
    "# Convert label to onehot\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=6)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=6)\n",
    "\n",
    "X_train = np.expand_dims(X_train, axis=2)\n",
    "X_test = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Neural Network\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(16, 3, activation='relu', input_shape=(5000, 1)))\n",
    "model.add(Conv1D(16, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(Conv1D(256, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(GlobalAveragePooling1D())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_name = 'deep_1'\n",
    "top_weights_path = 'model_' + str(model_name) + '.h5'\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(top_weights_path, monitor = 'val_acc', verbose = 1, save_best_only = True, save_weights_only = True), \n",
    "    EarlyStopping(monitor = 'val_acc', patience = 6, verbose = 1),\n",
    "    ReduceLROnPlateau(monitor = 'val_acc', factor = 0.1, patience = 3, verbose = 1),\n",
    "    CSVLogger('model_' + str(model_name) + '.log')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot model\n",
    "from keras.utils import plot_model\n",
    "plot_model(model,to_file='model_plot.png') # requires pydot and graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![model](model_plot.png){:height=\"36px\" width=\"36px\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fitting the Model (this will take a loooooooot of time)\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=100, validation_data = [X_test, y_test], callbacks = callbacks_list)\n",
    "\n",
    "\n",
    "model.load_weights(top_weights_path)\n",
    "loss, acc = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "#print('loss', loss)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Remark:*** \n",
    "The validation accuracy stops to improve after epoch 6, while the test accuracy goes above .90."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further ideas:\n",
    "* construct spectrograms\n",
    "* do deep learning on the spectrograms using 2D convolutions\n",
    "* model the time domension using a Long Short Term Memory Network (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
